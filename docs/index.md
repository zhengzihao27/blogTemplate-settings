---
hide:
  - navigation
  - toc
---



# 主页



<div class="grid cards" markdown>


-   :material-note:{ .lg .middle } __Discrete-Time Mean-Variance Strategy Based on Reinforcement Learning (Notes)__

    ---

    * 根据贝尔曼最优原则求解带熵正则的最优值函数，并给出相应的最优策略分布。
    * 证明了在给定最初容许控制下，策略评估后的策略迭代过程能够最终收敛到最优策略分布。
    * 参数化值函数和策略分布，设计RL算法，根据历史金融数据进行学习并估计参数。

    [:octicons-arrow-right-24: Note](./blog/posts/论文笔记/强化学习/1.基于强化学习的离散时间均值方差策略/基于强化学习的离散时间均值方差策略.md)

-   :material-language-python:{ .lg .middle } __Discrete-Time Mean-Variance Strategy Based on Reinforcement Learning (Code reproduction)__

    ---

    * Code reproduction
    * Original paper [link](https://arxiv.org/pdf/2312.15385)
      
    <figure markdown="span">
    ![b=1.1, a=0.3, sigma=0.2](./blog/posts/代码复现/1.基于强化学习的离散时间均值方差策略/images/Learning%20Curves_1.1_0.3_0.2_example.png){ height="330" }
    </figure>
    [:octicons-arrow-right-24: Code](./blog/posts/代码复现/1.基于强化学习的离散时间均值方差策略/code.md)
    

-   :material-language-python:{ .lg .middle } __Discrete-Time Exploratory-MV Algorithm__

    ---
    :material-language-python:{ .lg .middle }
    Install [`mkdocs-material`](#) with [`pip`](#) and get up
    and running in minutes

    [:octicons-arrow-right-24: Getting started](#)

</div>